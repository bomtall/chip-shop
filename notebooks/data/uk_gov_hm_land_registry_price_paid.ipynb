{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "import polars as pl\n",
    "\n",
    "from fryer import all as fryer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_postcode = fryer.data.uk_gov_ons_postcode_directory.read().select(\n",
    "    pl.col(\"postcode\"),\n",
    "    pl.col(\"longitude\"),\n",
    "    pl.col(\"latitude\"),\n",
    ")\n",
    "df_postcode.tail().collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = (\n",
    "    fryer.data.uk_gov_hm_land_registry_price_paid.read()\n",
    "    .with_columns(\n",
    "        month=pl.col(\"date\").dt.month_start(),\n",
    "        year=pl.col(\"date\").dt.strftime(\"%Y-01-01\").str.to_date(\"%Y-%m-%d\"),\n",
    "        postcode=pl.col(\"postcode\"),\n",
    "    )\n",
    "    .join(df_postcode, on=\"postcode\", how=\"left\")\n",
    ")\n",
    "\n",
    "df.tail().collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Postcodes where the join has failed\n",
    "df.filter(pl.col(\"longitude\").is_null()).collect()[\"postcode\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in (\"year\", \"month\"):\n",
    "    df_len = df.group_by(col).len().collect()\n",
    "    display(df_len.pipe(px.bar, x=col, y=\"len\", title=col))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_x = \"year\"\n",
    "for col in (\n",
    "    \"property_type\",\n",
    "    \"old_new\",\n",
    "    \"tenure_duration\",\n",
    "    \"transaction_type\",\n",
    "    \"record_status_monthly_file_only\",\n",
    "):\n",
    "    df_len = df.group_by([column_x, col]).len().collect()\n",
    "    display(\n",
    "        df_len.pipe(\n",
    "            px.bar,\n",
    "            x=column_x,\n",
    "            y=\"len\",\n",
    "            color=col,\n",
    "            title=col,\n",
    "            category_orders={\n",
    "                col: df_len.sort(by=\"len\", descending=True)[col].to_list()\n",
    "            },\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note, this does not necessarily tell us if the prices are increasing/decreasing due to houses being sold not being the same in time\n",
    "\n",
    "column_group_by = \"month\"\n",
    "column_value = \"price\"\n",
    "map_quantiles = {\n",
    "    f\"{column_value}_q{quantile:.2f}\": quantile\n",
    "    for quantile in [\n",
    "        # 0.0,\n",
    "        # 0.01,\n",
    "        0.05,\n",
    "        0.1,\n",
    "        0.25,\n",
    "        0.5,\n",
    "        0.75,\n",
    "        0.9,\n",
    "        0.95,\n",
    "        # 0.99,\n",
    "        # 1.0,\n",
    "    ]\n",
    "}\n",
    "columns_quantiles = list(map_quantiles.keys())\n",
    "\n",
    "(\n",
    "    df.group_by(column_group_by)\n",
    "    .agg(\n",
    "        **{\n",
    "            column_quantile: pl.col(column_value).quantile(quantile)\n",
    "            for column_quantile, quantile in map_quantiles.items()\n",
    "        }\n",
    "    )\n",
    "    .sort(by=column_group_by)\n",
    "    .collect()\n",
    "    .pipe(px.line, x=column_group_by, y=columns_quantiles, log_y=True)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note, this does not necessarily tell us if the prices are increasing/decreasing due to houses being sold not being the same in time\n",
    "\n",
    "columns_group_by = [\"month\", \"property_type\"]\n",
    "column_value = \"price\"\n",
    "map_quantiles = {\n",
    "    f\"{column_value}_q{quantile:.2f}\": quantile\n",
    "    for quantile in [\n",
    "        # 0.0,\n",
    "        # 0.01,\n",
    "        0.05,\n",
    "        0.1,\n",
    "        0.25,\n",
    "        0.5,\n",
    "        0.75,\n",
    "        0.9,\n",
    "        0.95,\n",
    "        # 0.99,\n",
    "        # 1.0,\n",
    "    ]\n",
    "}\n",
    "columns_quantiles = list(map_quantiles.keys())\n",
    "\n",
    "(\n",
    "    df.group_by(columns_group_by)\n",
    "    .agg(\n",
    "        **{\n",
    "            column_quantile: pl.col(column_value).quantile(quantile)\n",
    "            for column_quantile, quantile in map_quantiles.items()\n",
    "        }\n",
    "    )\n",
    "    .sort(by=columns_group_by)\n",
    "    .collect()\n",
    "    .pipe(\n",
    "        px.line,\n",
    "        x=columns_group_by[0],\n",
    "        y=columns_quantiles,\n",
    "        log_y=True,\n",
    "        facet_row=columns_group_by[1],\n",
    "        height=1_600,\n",
    "    )\n",
    "    .update_yaxes(matches=None)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note, this does not necessarily tell us if the prices are increasing/decreasing due to houses being sold not being the same in time\n",
    "\n",
    "columns_group_by = [\"month\", \"tenure_duration\"]\n",
    "column_value = \"price\"\n",
    "map_quantiles = {\n",
    "    f\"{column_value}_q{quantile:.2f}\": quantile\n",
    "    for quantile in [\n",
    "        # 0.0,\n",
    "        # 0.01,\n",
    "        0.05,\n",
    "        0.1,\n",
    "        0.25,\n",
    "        0.5,\n",
    "        0.75,\n",
    "        0.9,\n",
    "        0.95,\n",
    "        # 0.99,\n",
    "        # 1.0,\n",
    "    ]\n",
    "}\n",
    "columns_quantiles = list(map_quantiles.keys())\n",
    "\n",
    "(\n",
    "    df.group_by(columns_group_by)\n",
    "    .agg(\n",
    "        **{\n",
    "            column_quantile: pl.col(column_value).quantile(quantile)\n",
    "            for column_quantile, quantile in map_quantiles.items()\n",
    "        }\n",
    "    )\n",
    "    .sort(by=columns_group_by)\n",
    "    .collect()\n",
    "    .pipe(\n",
    "        px.line,\n",
    "        x=columns_group_by[0],\n",
    "        y=columns_quantiles,\n",
    "        log_y=True,\n",
    "        facet_row=columns_group_by[1],\n",
    "        height=1_600,\n",
    "    )\n",
    "    .update_yaxes(matches=None)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    df.filter(pl.col(\"county\") == \"GREATER LONDON\")\n",
    "    .group_by([\"year\", \"longitude\", \"latitude\"])\n",
    "    .agg(price=pl.col(\"price\").median())\n",
    "    .collect()\n",
    "    .pipe(\n",
    "        px.scatter_map,\n",
    "        lat=\"latitude\",\n",
    "        lon=\"longitude\",\n",
    "        color=\"price\",\n",
    "        opacity=0.25,\n",
    "        animation_frame=\"year\",\n",
    "    )\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
